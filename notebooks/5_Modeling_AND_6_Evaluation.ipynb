{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CRISP-DM: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:red;\">???? ⬇️<div> - For the Baseline Performance Test (see Aufgabenstellung) we apply the exact same modeling techniques to the raw csv and clkeaned csv (data preparation) and compare their AUC score. Does this meet the requirements?\n",
    "<div style=\"color:red;\">???? ⬇️<div> - What value should we try to reach for the ROC AUC? Does it suffice if we significantly improve the result from the raw csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:03:58.900709Z",
     "iopub.status.busy": "2024-07-02T20:03:58.900400Z",
     "iopub.status.idle": "2024-07-02T20:04:00.375314Z",
     "shell.execute_reply": "2024-07-02T20:04:00.374999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Unprepared Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Main workflow\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m X_train, X_test, y_train, y_test, test_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m models \u001b[38;5;241m=\u001b[39m prepare_models()\n\u001b[0;32m    100\u001b[0m trained_models \u001b[38;5;241m=\u001b[39m train_models(models, X_train, y_train)\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     29\u001b[0m test_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(test\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Ensure test data has the same columns in the same order\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m test_encoded \u001b[38;5;241m=\u001b[39m test_encoded\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39m\u001b[43mX_encoded\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Standardize the features\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# OVERFITTING: Standardization avoids overfitting by ensuring that all features have the same scale\u001b[39;00m\n\u001b[0;32m     35\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# Existing imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB  # Import for Naive Bayes\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, recall_score, precision_score, f1_score\n",
    "import joblib\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings for plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # High resolution figures\n",
    "\n",
    "def prepare_data(train, test):\n",
    "    # Data preparation\n",
    "    # TODO: Do this in data preparation\n",
    "    train.drop('Date', axis=1, inplace=True)  # Assuming Date isn't required\n",
    "    X = train.drop([\"WnvPresent\"], axis=1)\n",
    "    y = train['WnvPresent']\n",
    "    X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "    # Apply the same transformation to test data\n",
    "    test_encoded = pd.get_dummies(test.drop(['Date', 'Id'], axis=1), drop_first=True)\n",
    "    # Ensure test data has the same columns in the same order\n",
    "    test_encoded = test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "    # Standardize the features\n",
    "    # OVERFITTING: Standardization avoids overfitting by ensuring that all features have the same scale\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_encoded)\n",
    "    test_scaled = scaler.transform(test_encoded)  # Use the same scaler to transform test data\n",
    "\n",
    "    # Split the dataset into training and testing sets -> Zunächst wird das Modell wird mit 70% der Daten trainiert und anschließend validiert.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, test_scaled\n",
    "\n",
    "def prepare_models():\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        # 'Support Vector Machine': SVC(probability=True),\n",
    "        # 'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def train_models(models, X_train, y_train):\n",
    "    trained_models = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[name] = model\n",
    "    return trained_models\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, classifier_name):\n",
    "    # Changed 'normalize' to None to show actual counts in the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=None)  \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix: {classifier_name}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_models(trained_models, X_test, y_test, plot_cm=True):\n",
    "    results = {}\n",
    "    class_names = ['No WnvPresent', 'WnvPresent']  # Update as per your class names\n",
    "    for name, model in trained_models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        results[name] = {\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_prob),\n",
    "            'F1 Score': f1_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred)\n",
    "        }\n",
    "        if plot_cm:\n",
    "            plot_confusion_matrix(y_test, y_pred, class_names, name)  # Corrected function call\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Continue with your main workflow\n",
    "\n",
    "display(Markdown(\"## Unprepared Data\"))\n",
    "# Load datasets\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "# Main workflow\n",
    "X_train, X_test, y_train, y_test, test_scaled = prepare_data(train, test)\n",
    "models = prepare_models()\n",
    "trained_models = train_models(models, X_train, y_train)\n",
    "results_df = evaluate_models(trained_models, X_test, y_test, False)\n",
    "\n",
    "# Display results\n",
    "display(results_df)\n",
    "\n",
    "display(Markdown(\"## Prepared Data\"))\n",
    "# Load datasets\n",
    "train_cleaned = pd.read_csv('../data/cleaned_train.csv')\n",
    "test_cleaned = pd.read_csv('../data/cleaned_test.csv')\n",
    "# Main workflow\n",
    "X_train, X_test, y_train, y_test, test_scaled = prepare_data(train_cleaned, test_cleaned)\n",
    "models = prepare_models()\n",
    "trained_models = train_models(models, X_train, y_train)\n",
    "results_df = evaluate_models(trained_models, X_test, y_test)\n",
    "# Display results\n",
    "display(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_submission(model, test, filename='submission.csv'):\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
